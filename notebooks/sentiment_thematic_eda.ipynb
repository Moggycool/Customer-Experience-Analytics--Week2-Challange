{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da0e1c4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae93190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "# Sentiment & Thematic Analysis EDA\n",
    "## Quick EDA for Bank Reviews with Sentiment and Theme Insights\n",
    "\n",
    "**Note:** All data files are already available in `data/preprocessed/`\n",
    "\"\"\"\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 1. Setup and Load Data\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"üìÅ Current working directory:\", os.getcwd())\n",
    "\n",
    "# %%\n",
    "# Load data from the correct location\n",
    "# Files are in project_root/data/preprocessed, notebook is in notebooks/\n",
    "DATA_DIR = \"../data/preprocessed\"  # Go up one level from notebooks/ to project root, then into data/preprocessed\n",
    "\n",
    "files = {\n",
    "    'sentiment': 'sentiment_analyzed.csv',\n",
    "    'thematic': 'thematic_analysis.csv',\n",
    "    'thematic_summary': 'thematic_summary.csv',\n",
    "    'thematic_metrics': 'thematic_metrics.csv',\n",
    "    'processed': 'google_play_processed_reviews.csv',\n",
    "    'sentiment_report': 'sentiment_analyzed_report.json',\n",
    "    'thematic_report': 'thematic_analysis_report.json'\n",
    "}\n",
    "\n",
    "# Load files\n",
    "data = {}\n",
    "for name, file in files.items():\n",
    "    path = os.path.join(DATA_DIR, file)\n",
    "    try:\n",
    "        if file.endswith('.csv'):\n",
    "            data[name] = pd.read_csv(path)\n",
    "            print(f\"‚úÖ Loaded {name}: {len(data[name])} rows\")\n",
    "        elif file.endswith('.json'):\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                data[name] = json.load(f)\n",
    "            print(f\"‚úÖ Loaded {name}: JSON report\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {file}: {str(e)}\")\n",
    "        data[name] = None\n",
    "\n",
    "# %%\n",
    "# Quick preview\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA PREVIEW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if data['sentiment'] is not None:\n",
    "    print(\"\\nüìä Sentiment Data:\")\n",
    "    print(f\"Shape: {data['sentiment'].shape}\")\n",
    "    print(f\"Columns: {list(data['sentiment'].columns)}\")\n",
    "    \n",
    "    # Show sample with sentiment columns\n",
    "    sentiment_cols = ['sentiment_label', 'sentiment_score', 'rating', 'bank_name']\n",
    "    available_cols = [col for col in sentiment_cols if col in data['sentiment'].columns]\n",
    "    if available_cols:\n",
    "        display(data['sentiment'][available_cols].head())\n",
    "    \n",
    "    # Sentiment distribution\n",
    "    if 'sentiment_label' in data['sentiment'].columns:\n",
    "        dist = data['sentiment']['sentiment_label'].value_counts()\n",
    "        print(f\"\\nSentiment Distribution:\")\n",
    "        for label, count in dist.items():\n",
    "            pct = count / len(data['sentiment']) * 100\n",
    "            print(f\"  {label}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "if data['thematic'] is not None:\n",
    "    print(\"\\nüéØ Thematic Data:\")\n",
    "    print(f\"Shape: {data['thematic'].shape}\")\n",
    "    \n",
    "    # Show sample with theme columns\n",
    "    theme_cols = ['identified_themes', 'keywords', 'bank_name']\n",
    "    available_cols = [col for col in theme_cols if col in data['thematic'].columns]\n",
    "    if available_cols:\n",
    "        display(data['thematic'][available_cols].head())\n",
    "    \n",
    "    # Theme coverage\n",
    "    if 'identified_themes' in data['thematic'].columns:\n",
    "        with_themes = data['thematic']['identified_themes'].notna().sum()\n",
    "        pct = with_themes / len(data['thematic']) * 100\n",
    "        print(f\"\\nReviews with themes: {with_themes:,} ({pct:.1f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf5b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 2. Sentiment Analysis Dashboard\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "def sentiment_dashboard(df):\n",
    "    \"\"\"Create quick sentiment visualizations.\"\"\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=3,\n",
    "        subplot_titles=('Sentiment Distribution', 'Avg Sentiment by Bank', \n",
    "                       'Sentiment vs Rating', 'Score Distribution', \n",
    "                       'Bank-wise Sentiment', 'Rating Heatmap'),\n",
    "        specs=[[{'type': 'pie'}, {'type': 'bar'}, {'type': 'scatter'}],\n",
    "               [{'type': 'histogram'}, {'type': 'bar'}, {'type': 'heatmap'}]],\n",
    "        vertical_spacing=0.12,\n",
    "        horizontal_spacing=0.1\n",
    "    )\n",
    "    \n",
    "    # Pie chart\n",
    "    if 'sentiment_label' in df.columns:\n",
    "        counts = df['sentiment_label'].value_counts()\n",
    "        colors = {'positive': '#2ecc71', 'neutral': '#3498db', 'negative': '#e74c3c'}\n",
    "        fig.add_trace(\n",
    "            go.Pie(labels=counts.index, values=counts.values, hole=0.3,\n",
    "                  marker=dict(colors=[colors.get(label, '#95a5a6') for label in counts.index])),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # Avg sentiment by bank\n",
    "    if all(col in df.columns for col in ['bank_name', 'sentiment_score']):\n",
    "        avg = df.groupby('bank_name')['sentiment_score'].mean().sort_values()\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=avg.values, y=avg.index, orientation='h',\n",
    "                  marker_color='rgba(52, 152, 219, 0.7)',\n",
    "                  text=[f\"{val:.3f}\" for val in avg.values], textposition='auto'),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        fig.update_xaxes(title_text=\"Average Sentiment\", row=1, col=2)\n",
    "    \n",
    "    # Sentiment vs rating scatter\n",
    "    if all(col in df.columns for col in ['rating', 'sentiment_score']):\n",
    "        sample_size = min(1000, len(df))\n",
    "        sample = df.sample(sample_size, random_state=42) if len(df) > 1000 else df\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=sample['rating'], y=sample['sentiment_score'],\n",
    "                      mode='markers', opacity=0.6,\n",
    "                      marker=dict(size=8, color=sample['sentiment_score'],\n",
    "                                colorscale='RdYlGn', showscale=True)),\n",
    "            row=1, col=3\n",
    "        )\n",
    "        fig.update_xaxes(title_text=\"Rating\", row=1, col=3)\n",
    "        fig.update_yaxes(title_text=\"Sentiment Score\", row=1, col=3)\n",
    "    \n",
    "    # Score histogram\n",
    "    if 'sentiment_score' in df.columns:\n",
    "        fig.add_trace(\n",
    "            go.Histogram(x=df['sentiment_score'], nbinsx=30,\n",
    "                        marker_color='#9b59b6', opacity=0.7),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        fig.update_xaxes(title_text=\"Sentiment Score\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Count\", row=2, col=1)\n",
    "    \n",
    "    # Bank sentiment stacked\n",
    "    if all(col in df.columns for col in ['bank_name', 'sentiment_label']):\n",
    "        sentiment_by_bank = pd.crosstab(df['bank_name'], df['sentiment_label'], normalize='index')\n",
    "        colors = {'positive': '#2ecc71', 'neutral': '#3498db', 'negative': '#e74c3c'}\n",
    "        \n",
    "        for sentiment in ['positive', 'neutral', 'negative']:\n",
    "            if sentiment in sentiment_by_bank.columns:\n",
    "                fig.add_trace(\n",
    "                    go.Bar(x=sentiment_by_bank.index, y=sentiment_by_bank[sentiment],\n",
    "                          name=sentiment.capitalize(),\n",
    "                          marker_color=colors.get(sentiment, '#95a5a6')),\n",
    "                    row=2, col=2\n",
    "                )\n",
    "        fig.update_xaxes(title_text=\"Bank\", row=2, col=2, tickangle=45)\n",
    "        fig.update_yaxes(title_text=\"Percentage\", row=2, col=2)\n",
    "    \n",
    "    # Heatmap\n",
    "    if all(col in df.columns for col in ['rating', 'sentiment_label']):\n",
    "        heatmap = pd.crosstab(df['rating'], df['sentiment_label'], normalize='index')\n",
    "        fig.add_trace(\n",
    "            go.Heatmap(z=heatmap.values, x=heatmap.columns, y=heatmap.index,\n",
    "                      colorscale='RdYlGn', text=heatmap.values,\n",
    "                      texttemplate='%{text:.1%}', showscale=True),\n",
    "            row=2, col=3\n",
    "        )\n",
    "        fig.update_xaxes(title_text=\"Sentiment\", row=2, col=3)\n",
    "        fig.update_yaxes(title_text=\"Rating\", row=2, col=3)\n",
    "    \n",
    "    fig.update_layout(height=800, showlegend=True, \n",
    "                     title_text=\"Sentiment Analysis Dashboard\", title_font_size=16)\n",
    "    fig.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"=\"*80)\n",
    "    print(\"SENTIMENT SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    if 'sentiment_label' in df.columns:\n",
    "        total = len(df)\n",
    "        print(f\"\\nTotal Reviews: {total:,}\")\n",
    "        for label in ['positive', 'neutral', 'negative']:\n",
    "            if label in df['sentiment_label'].unique():\n",
    "                count = (df['sentiment_label'] == label).sum()\n",
    "                print(f\"  {label.title()}: {count:,} ({count/total*100:.1f}%)\")\n",
    "    \n",
    "    if 'sentiment_score' in df.columns:\n",
    "        print(f\"\\nüìà Score Statistics:\")\n",
    "        print(f\"  Mean: {df['sentiment_score'].mean():.3f}\")\n",
    "        print(f\"  Std: {df['sentiment_score'].std():.3f}\")\n",
    "        print(f\"  Min: {df['sentiment_score'].min():.3f}\")\n",
    "        print(f\"  Max: {df['sentiment_score'].max():.3f}\")\n",
    "    \n",
    "    # Bank-level summary\n",
    "    if all(col in df.columns for col in ['bank_name', 'sentiment_score']):\n",
    "        bank_stats = df.groupby('bank_name').agg({\n",
    "            'sentiment_score': 'mean',\n",
    "            'sentiment_label': lambda x: (x == 'positive').sum() / len(x) * 100\n",
    "        }).round(3)\n",
    "        bank_stats.columns = ['avg_score', 'positive_pct']\n",
    "        bank_stats = bank_stats.sort_values('avg_score', ascending=False)\n",
    "        \n",
    "        print(f\"\\nüè¶ Bank Performance (Top 3):\")\n",
    "        for i, (bank, row) in enumerate(bank_stats.head(3).iterrows(), 1):\n",
    "            print(f\"{i}. {bank}\")\n",
    "            print(f\"   Score: {row['avg_score']:.3f}\")\n",
    "            print(f\"   Positive: {row['positive_pct']:.1f}%\")\n",
    "\n",
    "# %%\n",
    "if data['sentiment'] is not None:\n",
    "    sentiment_dashboard(data['sentiment'])\n",
    "else:\n",
    "    print(\"‚ùå Sentiment data not available\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef27021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 3. Thematic Analysis Dashboard\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "def thematic_dashboard(df):\n",
    "    \"\"\"Create quick thematic visualizations.\"\"\"\n",
    "    \n",
    "    if 'identified_themes' not in df.columns:\n",
    "        print(\"‚ùå 'identified_themes' column not found in data\")\n",
    "        return\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Top Themes', 'Themes by Bank', \n",
    "                       'Theme Co-occurrence', 'Theme-Rating Box'),\n",
    "        specs=[[{'type': 'bar'}, {'type': 'heatmap'}],\n",
    "               [{'type': 'heatmap'}, {'type': 'box'}]],\n",
    "        vertical_spacing=0.15,\n",
    "        horizontal_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    # Theme distribution\n",
    "    all_themes = []\n",
    "    for themes in df['identified_themes'].fillna(''):\n",
    "        if isinstance(themes, str):\n",
    "            all_themes.extend([t.strip() for t in themes.split(',') if t.strip()])\n",
    "    \n",
    "    if all_themes:\n",
    "        theme_counts = pd.Series(all_themes).value_counts().head(15)\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=theme_counts.values, y=theme_counts.index,\n",
    "                  orientation='h', marker_color='rgba(46, 204, 113, 0.7)',\n",
    "                  text=[f\"{count:,}\" for count in theme_counts.values], textposition='auto'),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        fig.update_xaxes(title_text=\"Number of Reviews\", row=1, col=1)\n",
    "    \n",
    "    # Heatmap by bank\n",
    "    if 'bank_name' in df.columns:\n",
    "        bank_themes = {}\n",
    "        for bank in df['bank_name'].unique():\n",
    "            bank_df = df[df['bank_name'] == bank]\n",
    "            themes = []\n",
    "            for t in bank_df['identified_themes'].fillna(''):\n",
    "                if isinstance(t, str):\n",
    "                    themes.extend([theme.strip() for theme in t.split(',') if theme.strip()])\n",
    "            bank_themes[bank] = pd.Series(themes).value_counts().head(5).to_dict()\n",
    "        \n",
    "        if bank_themes:\n",
    "            all_unique_themes = sorted(set(theme for themes in bank_themes.values() for theme in themes.keys()))\n",
    "            heat_data = []\n",
    "            for bank in bank_themes.keys():\n",
    "                heat_data.append([bank_themes[bank].get(theme, 0) for theme in all_unique_themes])\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Heatmap(z=heat_data, x=all_unique_themes, y=list(bank_themes.keys()),\n",
    "                          colorscale='Viridis', showscale=True,\n",
    "                          colorbar=dict(title=\"Count\")),\n",
    "                row=1, col=2\n",
    "            )\n",
    "            fig.update_xaxes(title_text=\"Theme\", row=1, col=2, tickangle=45)\n",
    "            fig.update_yaxes(title_text=\"Bank\", row=1, col=2)\n",
    "    \n",
    "    # Theme co-occurrence\n",
    "    all_themes_list = []\n",
    "    for themes in df['identified_themes'].fillna(''):\n",
    "        if isinstance(themes, str):\n",
    "            theme_list = [t.strip() for t in themes.split(',') if t.strip()]\n",
    "            if len(theme_list) >= 2:\n",
    "                all_themes_list.append(theme_list)\n",
    "    \n",
    "    if all_themes_list:\n",
    "        flat_themes = [theme for sublist in all_themes_list for theme in sublist]\n",
    "        top_themes = pd.Series(flat_themes).value_counts().head(10).index.tolist()\n",
    "        \n",
    "        # Build co-occurrence matrix\n",
    "        co_matrix = np.zeros((len(top_themes), len(top_themes)))\n",
    "        for themes in all_themes_list:\n",
    "            for i, t1 in enumerate(top_themes):\n",
    "                if t1 in themes:\n",
    "                    for j, t2 in enumerate(top_themes):\n",
    "                        if t2 in themes and t1 != t2:\n",
    "                            co_matrix[i, j] += 1\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Heatmap(z=co_matrix, x=top_themes, y=top_themes,\n",
    "                      colorscale='Blues', showscale=True,\n",
    "                      colorbar=dict(title=\"Co-occurrence\")),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        fig.update_xaxes(title_text=\"Theme\", row=2, col=1, tickangle=45)\n",
    "        fig.update_yaxes(title_text=\"Theme\", row=2, col=1)\n",
    "    \n",
    "    # Theme-rating box plot\n",
    "    if 'rating' in df.columns:\n",
    "        all_themes_flat = []\n",
    "        for themes in df['identified_themes'].fillna(''):\n",
    "            if isinstance(themes, str):\n",
    "                all_themes_flat.extend([t.strip() for t in themes.split(',') if t.strip()])\n",
    "        \n",
    "        if all_themes_flat:\n",
    "            top_5 = pd.Series(all_themes_flat).value_counts().head(5).index.tolist()\n",
    "            \n",
    "            colors = px.colors.qualitative.Set2\n",
    "            for i, theme in enumerate(top_5):\n",
    "                theme_ratings = []\n",
    "                for idx, row in df.iterrows():\n",
    "                    if isinstance(row['identified_themes'], str) and theme in row['identified_themes']:\n",
    "                        theme_ratings.append(row['rating'])\n",
    "                if theme_ratings:\n",
    "                    fig.add_trace(\n",
    "                        go.Box(y=theme_ratings, name=theme,\n",
    "                              marker_color=colors[i % len(colors)]),\n",
    "                        row=2, col=2\n",
    "                    )\n",
    "            fig.update_yaxes(title_text=\"Rating\", row=2, col=2)\n",
    "            fig.update_xaxes(title_text=\"Theme\", row=2, col=2, tickangle=45)\n",
    "    \n",
    "    fig.update_layout(height=800, showlegend=False,\n",
    "                     title_text=\"Thematic Analysis Dashboard\", title_font_size=16)\n",
    "    fig.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"=\"*80)\n",
    "    print(\"THEMATIC SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    total = len(df)\n",
    "    with_themes = df['identified_themes'].notna().sum()\n",
    "    print(f\"\\nTotal Reviews: {total:,}\")\n",
    "    print(f\"Reviews with themes: {with_themes:,} ({with_themes/total*100:.1f}%)\")\n",
    "    \n",
    "    if all_themes:\n",
    "        avg_themes = len(all_themes) / with_themes if with_themes > 0 else 0\n",
    "        print(f\"Average themes per review: {avg_themes:.2f}\")\n",
    "        \n",
    "        print(f\"\\nüéØ Top 5 Themes:\")\n",
    "        for theme, count in pd.Series(all_themes).value_counts().head(5).items():\n",
    "            pct = count / len(all_themes) * 100\n",
    "            print(f\"  ‚Ä¢ {theme}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# %%\n",
    "if data['thematic'] is not None:\n",
    "    thematic_dashboard(data['thematic'])\n",
    "else:\n",
    "    print(\"‚ùå Thematic data not available\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 4. Combined Sentiment & Thematic Analysis\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "def combined_analysis(sentiment_df, thematic_df):\n",
    "    \"\"\"Combine sentiment and thematic analysis.\"\"\"\n",
    "    \n",
    "    # Merge data\n",
    "    merge_cols = ['review_id'] if 'review_id' in sentiment_df.columns and 'review_id' in thematic_df.columns else None\n",
    "    \n",
    "    if merge_cols:\n",
    "        combined = pd.merge(sentiment_df, thematic_df, on=merge_cols, how='inner')\n",
    "    else:\n",
    "        # Try to align by index\n",
    "        combined = sentiment_df.copy()\n",
    "        if len(sentiment_df) == len(thematic_df):\n",
    "            for col in thematic_df.columns:\n",
    "                if col not in combined.columns:\n",
    "                    combined[col] = thematic_df[col].values\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Cannot merge: dataframes have different lengths\")\n",
    "            return\n",
    "    \n",
    "    print(f\"Combined data: {len(combined)} reviews\")\n",
    "    \n",
    "    # Create visualization\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Avg Sentiment by Theme', 'Themes by Sentiment',\n",
    "                       'Positive vs Negative Themes', 'Theme-Sentiment Correlation'),\n",
    "        specs=[[{'type': 'bar'}, {'type': 'bar'}],\n",
    "               [{'type': 'bar'}, {'type': 'scatter'}]],\n",
    "        vertical_spacing=0.15,\n",
    "        horizontal_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    # Avg sentiment by theme\n",
    "    if all(col in combined.columns for col in ['identified_themes', 'sentiment_score']):\n",
    "        theme_scores = []\n",
    "        for idx, row in combined.iterrows():\n",
    "            if isinstance(row['identified_themes'], str):\n",
    "                themes = [t.strip() for t in row['identified_themes'].split(',') if t.strip()]\n",
    "                for theme in themes:\n",
    "                    theme_scores.append({'theme': theme, 'score': row['sentiment_score']})\n",
    "        \n",
    "        if theme_scores:\n",
    "            theme_df = pd.DataFrame(theme_scores)\n",
    "            # Filter themes with at least 5 occurrences\n",
    "            theme_counts = theme_df['theme'].value_counts()\n",
    "            valid_themes = theme_counts[theme_counts >= 5].index\n",
    "            theme_df = theme_df[theme_df['theme'].isin(valid_themes)]\n",
    "            \n",
    "            if len(theme_df) > 0:\n",
    "                avg_scores = theme_df.groupby('theme')['score'].mean().sort_values()\n",
    "                top_10 = avg_scores.tail(10)  # Top 10 by sentiment\n",
    "                fig.add_trace(\n",
    "                    go.Bar(x=top_10.values, y=top_10.index,\n",
    "                          orientation='h', marker_color='rgba(52, 152, 219, 0.7)'),\n",
    "                    row=1, col=1\n",
    "                )\n",
    "                fig.update_xaxes(title_text=\"Avg Sentiment\", row=1, col=1)\n",
    "    \n",
    "    # Themes by sentiment\n",
    "    if all(col in combined.columns for col in ['identified_themes', 'sentiment_label']):\n",
    "        # Get top 5 themes\n",
    "        all_themes = []\n",
    "        for themes in combined['identified_themes'].fillna(''):\n",
    "            if isinstance(themes, str):\n",
    "                all_themes.extend([t.strip() for t in themes.split(',') if t.strip()])\n",
    "        \n",
    "        if all_themes:\n",
    "            top_5 = pd.Series(all_themes).value_counts().head(5).index.tolist()\n",
    "            \n",
    "            # Count by sentiment\n",
    "            sentiment_data = {}\n",
    "            for sentiment in ['positive', 'neutral', 'negative']:\n",
    "                sentiment_df = combined[combined['sentiment_label'] == sentiment]\n",
    "                counts = []\n",
    "                for theme in top_5:\n",
    "                    count = sum(1 for t in sentiment_df['identified_themes'].fillna('') \n",
    "                               if isinstance(t, str) and theme in t)\n",
    "                    counts.append(count)\n",
    "                sentiment_data[sentiment] = counts\n",
    "            \n",
    "            colors = {'positive': '#2ecc71', 'neutral': '#3498db', 'negative': '#e74c3c'}\n",
    "            for sentiment, counts in sentiment_data.items():\n",
    "                fig.add_trace(\n",
    "                    go.Bar(x=top_5, y=counts, name=sentiment.capitalize(),\n",
    "                          marker_color=colors[sentiment]),\n",
    "                    row=1, col=2\n",
    "                )\n",
    "            fig.update_xaxes(title_text=\"Theme\", row=1, col=2, tickangle=45)\n",
    "            fig.update_yaxes(title_text=\"Count\", row=1, col=2)\n",
    "    \n",
    "    # Positive vs negative themes\n",
    "    if all(col in combined.columns for col in ['identified_themes', 'sentiment_label']):\n",
    "        pos_df = combined[combined['sentiment_label'] == 'positive']\n",
    "        neg_df = combined[combined['sentiment_label'] == 'negative']\n",
    "        \n",
    "        # Get top themes for each\n",
    "        pos_themes, neg_themes = [], []\n",
    "        \n",
    "        for themes in pos_df['identified_themes'].fillna(''):\n",
    "            if isinstance(themes, str):\n",
    "                pos_themes.extend([t.strip() for t in themes.split(',') if t.strip()])\n",
    "        \n",
    "        for themes in neg_df['identified_themes'].fillna(''):\n",
    "            if isinstance(themes, str):\n",
    "                neg_themes.extend([t.strip() for t in themes.split(',') if t.strip()])\n",
    "        \n",
    "        if pos_themes and neg_themes:\n",
    "            pos_top = pd.Series(pos_themes).value_counts().head(5)\n",
    "            neg_top = pd.Series(neg_themes).value_counts().head(5)\n",
    "            \n",
    "            themes = list(set(list(pos_top.index) + list(neg_top.index)))\n",
    "            pos_counts = [pos_top.get(t, 0) for t in themes]\n",
    "            neg_counts = [neg_top.get(t, 0) for t in themes]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Bar(x=themes, y=pos_counts, name='Positive',\n",
    "                      marker_color='#2ecc71'),\n",
    "                row=2, col=1\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Bar(x=themes, y=neg_counts, name='Negative',\n",
    "                      marker_color='#e74c3c'),\n",
    "                row=2, col=1\n",
    "            )\n",
    "            fig.update_xaxes(title_text=\"Theme\", row=2, col=1, tickangle=45)\n",
    "            fig.update_yaxes(title_text=\"Count\", row=2, col=1)\n",
    "    \n",
    "    # Theme-sentiment correlation\n",
    "    if all(col in combined.columns for col in ['identified_themes', 'sentiment_score']):\n",
    "        theme_scores = []\n",
    "        for idx, row in combined.iterrows():\n",
    "            if isinstance(row['identified_themes'], str):\n",
    "                themes = [t.strip() for t in row['identified_themes'].split(',') if t.strip()]\n",
    "                for theme in themes:\n",
    "                    theme_scores.append({'theme': theme, 'score': row['sentiment_score']})\n",
    "        \n",
    "        if theme_scores:\n",
    "            scores_df = pd.DataFrame(theme_scores)\n",
    "            theme_stats = scores_df.groupby('theme').agg({'score': ['mean', 'count']})\n",
    "            theme_stats.columns = ['avg_score', 'count']\n",
    "            theme_stats = theme_stats[theme_stats['count'] >= 5]\n",
    "            \n",
    "            if len(theme_stats) > 0:\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=theme_stats['count'], y=theme_stats['avg_score'],\n",
    "                             mode='markers+text', text=theme_stats.index,\n",
    "                             marker=dict(size=np.sqrt(theme_stats['count']) * 2,\n",
    "                                       color=theme_stats['avg_score'],\n",
    "                                       colorscale='RdYlGn', showscale=True),\n",
    "                             textposition='top center'),\n",
    "                    row=2, col=2\n",
    "                )\n",
    "                fig.update_xaxes(title_text=\"Occurrences\", row=2, col=2, type='log')\n",
    "                fig.update_yaxes(title_text=\"Avg Sentiment\", row=2, col=2)\n",
    "    \n",
    "    fig.update_layout(height=800, showlegend=True, barmode='group',\n",
    "                     title_text=\"Combined Sentiment & Thematic Analysis\", title_font_size=16)\n",
    "    fig.show()\n",
    "    \n",
    "    # Print insights\n",
    "    print(\"=\"*80)\n",
    "    print(\"COMBINED INSIGHTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if all(col in combined.columns for col in ['sentiment_label', 'identified_themes']):\n",
    "        # Most positive themes\n",
    "        pos_df = combined[combined['sentiment_label'] == 'positive']\n",
    "        pos_themes = []\n",
    "        for themes in pos_df['identified_themes'].fillna(''):\n",
    "            if isinstance(themes, str):\n",
    "                pos_themes.extend([t.strip() for t in themes.split(',') if t.strip()])\n",
    "        \n",
    "        if pos_themes:\n",
    "            top_pos = pd.Series(pos_themes).value_counts().head(3)\n",
    "            print(\"\\nüéØ Top Themes in POSITIVE Reviews:\")\n",
    "            for theme, count in top_pos.items():\n",
    "                pct = count / len(pos_themes) * 100\n",
    "                print(f\"  ‚Ä¢ {theme}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Most negative themes\n",
    "        neg_df = combined[combined['sentiment_label'] == 'negative']\n",
    "        neg_themes = []\n",
    "        for themes in neg_df['identified_themes'].fillna(''):\n",
    "            if isinstance(themes, str):\n",
    "                neg_themes.extend([t.strip() for t in themes.split(',') if t.strip()])\n",
    "        \n",
    "        if neg_themes:\n",
    "            top_neg = pd.Series(neg_themes).value_counts().head(3)\n",
    "            print(\"\\n‚ö†Ô∏è  Top Themes in NEGATIVE Reviews:\")\n",
    "            for theme, count in top_neg.items():\n",
    "                pct = count / len(neg_themes) * 100\n",
    "                print(f\"  ‚Ä¢ {theme}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# %%\n",
    "if data['sentiment'] is not None and data['thematic'] is not None:\n",
    "    combined_analysis(data['sentiment'], data['thematic'])\n",
    "else:\n",
    "    print(\"‚ùå Both sentiment and thematic data required for combined analysis\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5305d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 5. Export Insights\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "def export_insights(sentiment_df, thematic_df):\n",
    "    \"\"\"Export key insights to text file.\"\"\"\n",
    "    \n",
    "    insights = []\n",
    "    insights.append(\"=\"*80)\n",
    "    insights.append(\"BANK REVIEWS ANALYSIS - KEY INSIGHTS\")\n",
    "    insights.append(\"=\"*80)\n",
    "    insights.append(f\"Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    insights.append(\"\")\n",
    "    \n",
    "    # Sentiment insights\n",
    "    if sentiment_df is not None:\n",
    "        total = len(sentiment_df)\n",
    "        insights.append(\"üìà SENTIMENT ANALYSIS\")\n",
    "        insights.append(\"-\"*40)\n",
    "        insights.append(f\"Total Reviews Analyzed: {total:,}\")\n",
    "        \n",
    "        if 'sentiment_label' in sentiment_df.columns:\n",
    "            for label in ['positive', 'neutral', 'negative']:\n",
    "                if label in sentiment_df['sentiment_label'].unique():\n",
    "                    count = (sentiment_df['sentiment_label'] == label).sum()\n",
    "                    insights.append(f\"{label.title()}: {count:,} ({count/total*100:.1f}%)\")\n",
    "        \n",
    "        if 'sentiment_score' in sentiment_df.columns:\n",
    "            insights.append(f\"Average Sentiment Score: {sentiment_df['sentiment_score'].mean():.3f}\")\n",
    "    \n",
    "    # Thematic insights\n",
    "    if thematic_df is not None and 'identified_themes' in thematic_df.columns:\n",
    "        total = len(thematic_df)\n",
    "        with_themes = thematic_df['identified_themes'].notna().sum()\n",
    "        \n",
    "        insights.append(\"\\nüìä THEMATIC ANALYSIS\")\n",
    "        insights.append(\"-\"*40)\n",
    "        insights.append(f\"Reviews with Themes: {with_themes:,} ({with_themes/total*100:.1f}%)\")\n",
    "        \n",
    "        # Top themes\n",
    "        all_themes = []\n",
    "        for themes in thematic_df['identified_themes'].fillna(''):\n",
    "            if isinstance(themes, str):\n",
    "                all_themes.extend([t.strip() for t in themes.split(',') if t.strip()])\n",
    "        \n",
    "        if all_themes:\n",
    "            top_5 = pd.Series(all_themes).value_counts().head(5)\n",
    "            insights.append(\"\\nTop 5 Themes:\")\n",
    "            for theme, count in top_5.items():\n",
    "                pct = count / len(all_themes) * 100\n",
    "                insights.append(f\"  ‚Ä¢ {theme}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Combined insights\n",
    "    if sentiment_df is not None and 'bank_name' in sentiment_df.columns:\n",
    "        bank_metrics = sentiment_df.groupby('bank_name')['sentiment_score'].mean().sort_values(ascending=False)\n",
    "        \n",
    "        insights.append(\"\\nüè¶ BANK PERFORMANCE\")\n",
    "        insights.append(\"-\"*40)\n",
    "        if len(bank_metrics) > 0:\n",
    "            insights.append(f\"Best Performing Bank: {bank_metrics.index[0]} (Score: {bank_metrics.iloc[0]:.3f})\")\n",
    "            insights.append(f\"Worst Performing Bank: {bank_metrics.index[-1]} (Score: {bank_metrics.iloc[-1]:.3f})\")\n",
    "    \n",
    "    # Recommendations\n",
    "    insights.append(\"\\nüéØ RECOMMENDATIONS\")\n",
    "    insights.append(\"-\"*40)\n",
    "    insights.append(\"1. Address themes frequently mentioned in negative reviews\")\n",
    "    insights.append(\"2. Investigate low-performing banks for systemic issues\")\n",
    "    insights.append(\"3. Monitor theme trends for proactive improvements\")\n",
    "    insights.append(\"4. Use sentiment-theme correlation for targeted feature development\")\n",
    "    insights.append(\"5. Consider A/B testing for high-impact theme improvements\")\n",
    "    \n",
    "    # Save to file\n",
    "    output_dir = \"data/preprocessed\"  # Save in notebooks/data/preprocessed\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, \"analysis_insights.txt\")\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(insights))\n",
    "    \n",
    "    print(f\"‚úÖ Insights saved to: {output_path}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"KEY INSIGHTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    for line in insights[:20]:  # Print first 20 lines\n",
    "        print(line)\n",
    "\n",
    "# %%\n",
    "export_insights(data['sentiment'], data['thematic'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a367a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 6. Summary\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä Analysis Completed:\")\n",
    "print(\"  ‚úÖ Sentiment Analysis Dashboard\")\n",
    "print(\"  ‚úÖ Thematic Analysis Dashboard\")\n",
    "print(\"  ‚úÖ Combined Sentiment & Thematic Analysis\")\n",
    "print(\"  ‚úÖ Key Insights Exported\")\n",
    "\n",
    "print(\"\\nüìÅ Files Available:\")\n",
    "for name, df in data.items():\n",
    "    if df is not None:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            print(f\"  ‚Ä¢ {name}: {len(df):,} rows\")\n",
    "        else:\n",
    "            print(f\"  ‚Ä¢ {name}: JSON report\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"  1. Review interactive dashboards above\")\n",
    "print(\"  2. Check notebooks/data/preprocessed/analysis_insights.txt\")\n",
    "print(\"  3. Use insights for strategic decision making\")\n",
    "print(\"  4. Consider time-series analysis for trends\")\n",
    "print(\"  5. Explore deeper correlations with statistical tests\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Ready for presentation and decision-making!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03603d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
