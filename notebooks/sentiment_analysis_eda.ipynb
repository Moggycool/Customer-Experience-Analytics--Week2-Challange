{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18d83853",
   "metadata": {},
   "source": [
    "# Task 2: Sentiment and Thematic Analysis\n",
    "## 1 – Imports & Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "import spacy\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Get absolute path to the project root\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Add project root to Python path\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "print(\"Project Root Added:\", ROOT_DIR)\n",
    "\n",
    "\n",
    "# Import modular classes\n",
    "from src.sentiment_analysis import SentimentAnalyzer\n",
    "from src.thematic_analysis import ThematicAnalyzer\n",
    "from src.pipeline import ReviewPipeline\n",
    "\n",
    "# Plot styling\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c9b23",
   "metadata": {},
   "source": [
    "\n",
    "## 2 – Download NLTK Lexicons / Stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk downloader\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585ede9f",
   "metadata": {},
   "source": [
    "\n",
    "## 3 – Load Preprocessed Reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af7f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Reviews\n",
    "\n",
    "df = pd.read_csv(\"../data/preprocessed/google_play_processed_reviews.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe13471",
   "metadata": {},
   "source": [
    "\n",
    "## 4 – Sentiment Analysis Using `SentimentAnalyzer` Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sentiment analysis\n",
    "sentiment_analyzer = SentimentAnalyzer(df, text_column=\"clean_text\")\n",
    "df_sentiment = sentiment_analyzer.analyze_sentiment()\n",
    "df_sentiment[[\"clean_text\", \"rating\", \"sentiment_score\", \"sentiment_label\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe6bea6",
   "metadata": {},
   "source": [
    "\n",
    "## 5 – Lexicon-Based Sentiment (TextBlob & VADER) for Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b9d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TextBlob\n",
    "df_sentiment[\"tb_polarity\"] = df_sentiment[\"clean_text\"].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "df_sentiment[\"tb_subjectivity\"] = df_sentiment[\"clean_text\"].apply(lambda x: TextBlob(str(x)).sentiment.subjectivity)\n",
    "\n",
    "def polarity_to_label(p):\n",
    "    if p > 0.1:\n",
    "        return \"positive\"\n",
    "    elif p < -0.1:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "df_sentiment[\"tb_sentiment\"] = df_sentiment[\"tb_polarity\"].apply(polarity_to_label)\n",
    "\n",
    "# VADER\n",
    "def vader_compound(text):\n",
    "    return sia.polarity_scores(str(text))[\"compound\"]\n",
    "\n",
    "df_sentiment[\"vader_compound\"] = df_sentiment[\"clean_text\"].apply(vader_compound)\n",
    "\n",
    "def vader_label(c):\n",
    "    if c >= 0.05:\n",
    "        return \"positive\"\n",
    "    elif c <= -0.05:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "df_sentiment[\"vader_sentiment\"] = df_sentiment[\"vader_compound\"].apply(vader_label)\n",
    "print(df_sentiment.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad5d36",
   "metadata": {},
   "source": [
    "\n",
    "## 6 – Thematic Analysis Using `ThematicAnalyzer` Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97ef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Thematic Analyzer\n",
    "thematic_analyzer = ThematicAnalyzer(df_sentiment, text_column=\"clean_text\")\n",
    "df_themes = thematic_analyzer.extract_keywords(top_n=10)\n",
    "df_themes = thematic_analyzer.assign_themes()\n",
    "df_themes[[\"clean_text\", \"keywords\", \"identified_themes\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2181b563",
   "metadata": {},
   "source": [
    "## 7 – Frequency-Based (Bag of Words) & TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa3a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Application of Frequency-Based (Bag of Words) & TF-IDF\n",
    "df_themes[\"clean_text\"] = df_themes[\"clean_text\"].str.lower()\n",
    "\n",
    "# Bag of Words\n",
    "count_vec = CountVectorizer(stop_words=\"english\")\n",
    "X_counts = count_vec.fit_transform(df_themes[\"clean_text\"])\n",
    "word_counts = np.asarray(X_counts.sum(axis=0)).flatten()\n",
    "vocab = np.array(count_vec.get_feature_names_out())\n",
    "freq_df = pd.DataFrame({\"word\": vocab, \"count\": word_counts}).sort_values(\"count\", ascending=False)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vec = TfidfVectorizer(stop_words=\"english\")\n",
    "X_tfidf = tfidf_vec.fit_transform(df_themes[\"clean_text\"])\n",
    "tfidf_means = np.asarray(X_tfidf.mean(axis=0)).flatten()\n",
    "vocab_tfidf = np.array(tfidf_vec.get_feature_names_out())\n",
    "tfidf_df = pd.DataFrame({\"word\": vocab_tfidf, \"tfidf\": tfidf_means}).sort_values(\"tfidf\", ascending=False)\n",
    "# Show top 10 frequent words\n",
    "print(\"Top 10 Frequent Words:\")\n",
    "display(freq_df.head(10))\n",
    "\n",
    "# Show top 10 TF-IDF words\n",
    "print(\"\\nTop 10 TF-IDF Words:\")\n",
    "display(tfidf_df.head(10))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Top 10 frequent words plot\n",
    "top_n = 10\n",
    "top_freq = freq_df.head(top_n)\n",
    "plt.bar(top_freq[\"word\"], top_freq[\"count\"])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top Frequent Words (Bag-of-Words)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df000d92",
   "metadata": {},
   "source": [
    "## 8 – Topic Modeling (LDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e753bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize & remove stopwords\n",
    "df_themes[\"tokens\"] = df_themes[\"clean_text\"].str.split()\n",
    "df_themes[\"tokens_nostop\"] = df_themes[\"tokens\"].apply(lambda words: [w for w in words if w not in stop_words])\n",
    "\n",
    "dictionary = Dictionary(df_themes[\"tokens_nostop\"])\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in df_themes[\"tokens_nostop\"]]\n",
    "\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=2, passes=10, random_state=42)\n",
    "topics = lda_model.show_topics(num_topics=2, num_words=10, formatted=False)\n",
    "\n",
    "for i, topic in topics:\n",
    "    print(f\"\\n--- Topic {i+1} ---\")\n",
    "    for word, weight in topic:\n",
    "        print(f\"{word:15s}  weight={weight:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0683021a",
   "metadata": {},
   "source": [
    "## 9 – Part-of-Speech Tagging (Noun Extraction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c32cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PoS Tagging\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "df_themes[\"nouns\"] = df_themes[\"clean_text\"].apply(lambda x: [token.text for token in nlp(str(x)) if token.pos_ == \"NOUN\"])\n",
    "df_themes[[\"clean_text\", \"nouns\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134f9036",
   "metadata": {},
   "source": [
    "\n",
    "## 10 – Visualizations\n",
    "### Sentiment Distribution (Pipeline vs TextBlob vs VADER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7841043",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualizing Sentiment Distribution (Pipeline vs TextBlob vs VADER)\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x=\"sentiment_label\", data=df_themes, palette=\"viridis\")\n",
    "plt.title(\"Pipeline Sentiment Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x=\"tb_sentiment\", data=df_themes, palette=\"plasma\")\n",
    "plt.title(\"TextBlob Sentiment Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x=\"vader_sentiment\", data=df_themes, palette=\"coolwarm\")\n",
    "plt.title(\"VADER Sentiment Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf3370",
   "metadata": {},
   "source": [
    "\n",
    "### Themes Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920640f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Theme distribution visualization\n",
    "top_themes = df_themes[\"identified_themes\"].value_counts().nlargest(10)\n",
    "sns.barplot(x=top_themes.values, y=top_themes.index, palette=\"Set2\")\n",
    "plt.title(\"Top Themes Across Reviews\")\n",
    "plt.xlabel(\"Number of Reviews\")\n",
    "plt.ylabel(\"Theme\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc217fa",
   "metadata": {},
   "source": [
    "### Sentiment Score vs Rating Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f131d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sentiment Score vs Rating Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "axes[0].scatter(df_themes[\"rating\"], df_themes[\"sentiment_score\"])\n",
    "axes[0].set_title(\"Pipeline Sentiment vs Rating\")\n",
    "axes[0].set_xlabel(\"Star Rating\")\n",
    "axes[0].set_ylabel(\"Sentiment Score\")\n",
    "\n",
    "axes[1].scatter(df_themes[\"rating\"], df_themes[\"tb_polarity\"])\n",
    "axes[1].set_title(\"TextBlob Polarity vs Rating\")\n",
    "axes[1].set_xlabel(\"Star Rating\")\n",
    "axes[1].set_ylabel(\"Polarity (-1 to 1)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914c91bf",
   "metadata": {},
   "source": [
    "\n",
    "## 11 – Save Processed Data (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb3e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save Processed Data (Optional)\n",
    "\n",
    "import os\n",
    "\n",
    "# Save to project_root/data/preprocessed/\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # one level up from notebooks/\n",
    "output_dir = os.path.join(project_root, \"data\", \"preprocessed\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(output_dir, \"sentiment_preprocessed.csv\")\n",
    "df_themes.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved processed data to {output_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
