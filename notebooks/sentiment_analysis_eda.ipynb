{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18d83853",
   "metadata": {},
   "source": [
    "# Task 2: Sentiment and Thematic Analysis\n",
    "## 1 â€“ Imports & Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_pipeline_prod.py\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import spacy\n",
    "\n",
    "# ------------------------\n",
    "# Setup Logging\n",
    "# ------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# Paths\n",
    "# ------------------------\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\", \"preprocessed\")\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "INPUT_PATH = os.path.join(DATA_DIR, \"google_play_processed_reviews.csv\")\n",
    "OUTPUT_PATH = os.path.join(DATA_DIR, \"sentiment_preprocessed.csv\")\n",
    "\n",
    "# Add project src to path\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "# ------------------------\n",
    "# Import Pipeline Modules\n",
    "# ------------------------\n",
    "from src.sentiment_analysis import SentimentAnalyzer\n",
    "from src.thematic_analysis import ThematicAnalyzer\n",
    "from src.pipeline import ReviewPipeline\n",
    "\n",
    "# ------------------------\n",
    "# NLTK Setup\n",
    "# ------------------------\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a51e8",
   "metadata": {},
   "source": [
    "## Load Preprocessed Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4f933",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------\n",
    "# Load Data\n",
    "# ------------------------\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_PATH)\n",
    "    logging.info(f\"Loaded {len(df)} reviews from {INPUT_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Input file not found: {INPUT_PATH}\")\n",
    "    raise\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cf06a6",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Run Pipeline\n",
    "# ------------------------\n",
    "pipeline = ReviewPipeline(input_path=INPUT_PATH, output_path=OUTPUT_PATH)\n",
    "df_final = pipeline.run_pipeline()\n",
    "\n",
    "# ------------------------\n",
    "# Lexicon-Based Sentiment (TextBlob & VADER)\n",
    "# ------------------------\n",
    "sentiment_analyzer = SentimentAnalyzer(df, text_column=\"clean_text\")\n",
    "df_sentiment = sentiment_analyzer.analyze_sentiment()\n",
    "df_sentiment[[\"clean_text\", \"rating\", \"sentiment_score\", \"sentiment_label\"]].head()\n",
    "\n",
    "logging.info(\"Running TextBlob and VADER sentiment scoring...\")\n",
    "df_final[\"tb_polarity\"] = df_final[\"clean_text\"].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "df_final[\"tb_subjectivity\"] = df_final[\"clean_text\"].apply(lambda x: TextBlob(str(x)).sentiment.subjectivity)\n",
    "\n",
    "def polarity_to_label(p):\n",
    "    if p > 0.1:\n",
    "        return \"positive\"\n",
    "    elif p < -0.1:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "df_final[\"tb_sentiment\"] = df_final[\"tb_polarity\"].apply(polarity_to_label)\n",
    "\n",
    "df_final[\"vader_compound\"] = df_final[\"clean_text\"].apply(lambda x: sia.polarity_scores(str(x))[\"compound\"])\n",
    "\n",
    "def vader_label(c):\n",
    "    if c >= 0.05:\n",
    "        return \"positive\"\n",
    "    elif c <= -0.05:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "df_final[\"vader_sentiment\"] = df_final[\"vader_compound\"].apply(vader_label)\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cf5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis\n",
    "sentiment_analyzer = SentimentAnalyzer(df, text_column=\"clean_text\")\n",
    "df_sentiment = sentiment_analyzer.analyze_sentiment()\n",
    "df_sentiment[[\"clean_text\", \"rating\", \"sentiment_score\", \"sentiment_label\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef9d821",
   "metadata": {},
   "source": [
    "## Thematic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d024142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thematic Analysis\n",
    "thematic_analyzer = ThematicAnalyzer(df_sentiment, text_column=\"clean_text\")\n",
    "df_themes = thematic_analyzer.extract_keywords(top_n=10)\n",
    "df_themes = thematic_analyzer.assign_themes()\n",
    "df_themes[[\"clean_text\", \"keywords\", \"identified_themes\"]].head()\n",
    "# Ensure all sentiment columns are carried over\n",
    "#for col in [\"tb_polarity\", \"tb_subjectivity\", \"tb_sentiment\", \"vader_compound\", \"vader_sentiment\"]:\n",
    "    #if col in df_sentiment.columns:\n",
    "        #df_themes[col] = df_sentiment[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031a72b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Frequency-Based & TF-IDF\n",
    "# ------------------------\n",
    "logging.info(\"Computing Bag-of-Words and TF-IDF...\")\n",
    "\n",
    "df_final[\"clean_text\"] = df_final[\"clean_text\"].str.lower()\n",
    "\n",
    "# Bag of Words\n",
    "count_vec = CountVectorizer(stop_words=\"english\")\n",
    "X_counts = count_vec.fit_transform(df_final[\"clean_text\"])\n",
    "word_counts = np.asarray(X_counts.sum(axis=0)).flatten()\n",
    "vocab = np.array(count_vec.get_feature_names_out())\n",
    "freq_df = pd.DataFrame({\"word\": vocab, \"count\": word_counts}).sort_values(\"count\", ascending=False)\n",
    "freq_df.to_csv(os.path.join(DATA_DIR, \"freq_words.csv\"), index=False)\n",
    "\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vec = TfidfVectorizer(stop_words=\"english\")\n",
    "X_tfidf = tfidf_vec.fit_transform(df_final[\"clean_text\"])\n",
    "tfidf_means = np.asarray(X_tfidf.mean(axis=0)).flatten()\n",
    "vocab_tfidf = np.array(tfidf_vec.get_feature_names_out())\n",
    "tfidf_df = pd.DataFrame({\"word\": vocab_tfidf, \"tfidf\": tfidf_means}).sort_values(\"tfidf\", ascending=False)\n",
    "tfidf_df.to_csv(os.path.join(DATA_DIR, \"tfidf_words.csv\"), index=False)\n",
    "# Show top 10 TF-IDF words\n",
    "print(\"\\nTop 10 TF-IDF Words:\")\n",
    "display(tfidf_df.head(10))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Top 10 frequent words plot\n",
    "top_n = 10\n",
    "top_freq = freq_df.head(top_n)\n",
    "plt.bar(top_freq[\"word\"], top_freq[\"count\"])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top Frequent Words (Bag-of-Words)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d96996",
   "metadata": {},
   "source": [
    "### Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6908f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------\n",
    "# Topic Modeling (LDA)\n",
    "# ------------------------\n",
    "logging.info(\"Performing LDA topic modeling...\")\n",
    "df_final[\"tokens\"] = df_final[\"clean_text\"].str.split()\n",
    "df_final[\"tokens_nostop\"] = df_final[\"tokens\"].apply(lambda words: [w for w in words if w not in stop_words])\n",
    "\n",
    "dictionary = Dictionary(df_final[\"tokens_nostop\"])\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in df_final[\"tokens_nostop\"]]\n",
    "\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=2, passes=10, random_state=42)\n",
    "topics = lda_model.show_topics(num_topics=2, num_words=10, formatted=False)\n",
    "\n",
    "for i, topic in topics:\n",
    "    logging.info(f\"--- Topic {i+1} ---\")\n",
    "    for word, weight in topic:\n",
    "        logging.info(f\"{word:15s} weight={weight:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a522f",
   "metadata": {},
   "source": [
    "### PoS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57024e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------\n",
    "# Part-of-Speech Tagging (Nouns)\n",
    "# ------------------------\n",
    "logging.info(\"Extracting nouns using spaCy...\")\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    logging.warning(\"spaCy model not found. Downloading...\")\n",
    "    from spacy.cli import download\n",
    "    download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "df_final[\"nouns\"] = df_final[\"clean_text\"].apply(lambda x: [token.text for token in nlp(str(x)) if token.pos_ == \"NOUN\"])\n",
    "df_final[[\"clean_text\", \"nouns\"]].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907521d4",
   "metadata": {},
   "source": [
    "## Save Processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ff4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------\n",
    "# Save Final Processed Data\n",
    "# ------------------------\n",
    "df_final.to_csv(OUTPUT_PATH, index=False)\n",
    "logging.info(f\"Final processed data saved to {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813288b0",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8104492",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------\n",
    "# Optional Visualizations\n",
    "# ------------------------\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)\n",
    "\n",
    "# Sentiment Distribution\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x=\"sentiment_label\", data=df_final, palette=\"viridis\")\n",
    "plt.title(\"Pipeline Sentiment Distribution\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Top Themes\n",
    "top_themes = df_final[\"identified_themes\"].value_counts().nlargest(10)\n",
    "sns.barplot(x=top_themes.values, y=top_themes.index, palette=\"Set2\")\n",
    "plt.title(\"Top Themes Across Reviews\")\n",
    "plt.xlabel(\"Number of Reviews\")\n",
    "plt.ylabel(\"Theme\")\n",
    "plt.show()\n",
    "\n",
    "# Sentiment Score vs Rating Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "axes[0].scatter(df_themes[\"rating\"], df_themes[\"sentiment_score\"])\n",
    "axes[0].set_title(\"Pipeline Sentiment vs Rating\")\n",
    "axes[0].set_xlabel(\"Star Rating\")\n",
    "axes[0].set_ylabel(\"Sentiment Score\")\n",
    "plt.show()\n",
    "\n",
    "#axes[1].scatter(df_themes[\"rating\"], df_themes[\"tb_polarity\"])\n",
    "#axes[1].set_title(\"TextBlob Polarity vs Rating\")\n",
    "#axes[1].set_xlabel(\"Star Rating\")\n",
    "#axes[1].set_ylabel(\"Polarity (-1 to 1)\")\n",
    "#plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
